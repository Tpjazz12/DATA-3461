{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "49cf8381",
      "metadata": {
        "id": "49cf8381"
      },
      "source": [
        "# Lab 6\n",
        "\n",
        "Scikit learn provides a large variety of algorithms for some common Machine Learning tasks, such as:\n",
        "\n",
        "* Classification\n",
        "* Regression\n",
        "* Clustering\n",
        "* Feature Selection\n",
        "* Anomaly Detection\n",
        "\n",
        "It also provides some datasets that you can use to test these algorithms:\n",
        "\n",
        "* Classification Datasets:\n",
        "    * Breast cancer wisconsin\n",
        "    * Iris plants (3-classes)\n",
        "    * Optical recognition of handwritten digits (10-classes)\n",
        "    * Wine (n-classes)\n",
        "\n",
        "* Regression Datasets:\n",
        "    * Boston house prices\n",
        "    * Diabetes\n",
        "    * Linnerrud (multiple regression)\n",
        "    * California Housing\n",
        "\n",
        "* Image:\n",
        "    * The Olivetti faces\n",
        "    * The Labeled Faces in the Wild face recognition\n",
        "    * Forest covertypes\n",
        "\n",
        "* NLP:\n",
        "    * News group\n",
        "    * Reuters Corpus Volume I\n",
        "\n",
        "* Other:\n",
        "    * Kddcup 99- Intrusion Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4e3b6e9",
      "metadata": {
        "id": "d4e3b6e9"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1. Use the full [Kddcup](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) dataset to compare classification performance of 3 different classifiers.\n",
        "    * Separate the data into train, validation, and test.\n",
        "    * Use accuracy as the metric for assessing performance.\n",
        "    * For each classifier, identify the hyperparameters. Perform optimization over at least 2 hyperparameters.   \n",
        "    * Compare the performance of the optimal configuration of the classifiers.\n",
        "\n",
        "2. Pick the best algorithm in question 1. Create an ensemble of at least 25 models, and use them for the classification task. Identify the top and bottom 10% of the data in terms of uncertainty of the decision.\n",
        "\n",
        "3. Use 2 different feature selection algorithm to identify the 10 most important features for the task in question 1. Retrain classifiers in question 1 with just this subset of features and compare performance.\n",
        "\n",
        "4. Use the same data, removing the labels, and compare performance of 3 different clustering algorithms. Can you find clusters for each of the classes in question 1?\n",
        "\n",
        "5. Can you identify any clusters within the top/botton 10% identified in 2. What are their characteristics?\n",
        "\n",
        "6. Use the \"SA\" dataset to compare the performance of 3 different anomaly detection algorithms.\n",
        "\n",
        "7. Create a subsample of 250 datapoints, redo question 6, using Leave-one-out as the method of evaluation.\n",
        "\n",
        "8. Use the feature selection algorithm to identify the 5 most important features for the task in question 6, for each algorithm. Does the anomaly detection improve using less features?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef18662c",
      "metadata": {
        "id": "ef18662c"
      },
      "source": [
        "## Quick look at the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9f1c631a",
      "metadata": {
        "id": "9f1c631a"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_kddcup99\n",
        "D=fetch_kddcup99()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7d561eff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d561eff",
        "outputId": "ce231439-6407-434e-b7b7-2c08c201a5ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "dir(D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "875d2d16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "875d2d16",
        "outputId": "dedb231c-2857-4cce-c9dc-c73b1917fae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _kddcup99_dataset:\n",
            "\n",
            "Kddcup 99 dataset\n",
            "-----------------\n",
            "\n",
            "The KDD Cup '99 dataset was created by processing the tcpdump portions\n",
            "of the 1998 DARPA Intrusion Detection System (IDS) Evaluation dataset,\n",
            "created by MIT Lincoln Lab [2]_. The artificial data (described on the `dataset's\n",
            "homepage <https://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html>`_) was\n",
            "generated using a closed network and hand-injected attacks to produce a\n",
            "large number of different types of attack with normal activity in the\n",
            "background. As the initial goal was to produce a large training set for\n",
            "supervised learning algorithms, there is a large proportion (80.1%) of\n",
            "abnormal data which is unrealistic in real world, and inappropriate for\n",
            "unsupervised anomaly detection which aims at detecting 'abnormal' data, i.e.:\n",
            "\n",
            "* qualitatively different from normal data\n",
            "* in large minority among the observations.\n",
            "\n",
            "We thus transform the KDD Data set into two different data sets: SA and SF.\n",
            "\n",
            "* SA is obtained by simply selecting all the normal data, and a small\n",
            "  proportion of abnormal data to gives an anomaly proportion of 1%.\n",
            "\n",
            "* SF is obtained as in [3]_\n",
            "  by simply picking up the data whose attribute logged_in is positive, thus\n",
            "  focusing on the intrusion attack, which gives a proportion of 0.3% of\n",
            "  attack.\n",
            "\n",
            "* http and smtp are two subsets of SF corresponding with third feature\n",
            "  equal to 'http' (resp. to 'smtp').\n",
            "\n",
            "General KDD structure :\n",
            "\n",
            "    ================      ==========================================\n",
            "    Samples total         4898431\n",
            "    Dimensionality        41\n",
            "    Features              discrete (int) or continuous (float)\n",
            "    Targets               str, 'normal.' or name of the anomaly type\n",
            "    ================      ==========================================\n",
            "\n",
            "    SA structure :\n",
            "\n",
            "    ================      ==========================================\n",
            "    Samples total         976158\n",
            "    Dimensionality        41\n",
            "    Features              discrete (int) or continuous (float)\n",
            "    Targets               str, 'normal.' or name of the anomaly type\n",
            "    ================      ==========================================\n",
            "\n",
            "    SF structure :\n",
            "\n",
            "    ================      ==========================================\n",
            "    Samples total         699691\n",
            "    Dimensionality        4\n",
            "    Features              discrete (int) or continuous (float)\n",
            "    Targets               str, 'normal.' or name of the anomaly type\n",
            "    ================      ==========================================\n",
            "\n",
            "    http structure :\n",
            "\n",
            "    ================      ==========================================\n",
            "    Samples total         619052\n",
            "    Dimensionality        3\n",
            "    Features              discrete (int) or continuous (float)\n",
            "    Targets               str, 'normal.' or name of the anomaly type\n",
            "    ================      ==========================================\n",
            "\n",
            "    smtp structure :\n",
            "\n",
            "    ================      ==========================================\n",
            "    Samples total         95373\n",
            "    Dimensionality        3\n",
            "    Features              discrete (int) or continuous (float)\n",
            "    Targets               str, 'normal.' or name of the anomaly type\n",
            "    ================      ==========================================\n",
            "\n",
            ":func:`sklearn.datasets.fetch_kddcup99` will load the kddcup99 dataset; it\n",
            "returns a dictionary-like object with the feature matrix in the ``data`` member\n",
            "and the target values in ``target``. The \"as_frame\" optional argument converts\n",
            "``data`` into a pandas DataFrame and ``target`` into a pandas Series. The\n",
            "dataset will be downloaded from the web if necessary.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    .. [2] Analysis and Results of the 1999 DARPA Off-Line Intrusion\n",
            "           Detection Evaluation, Richard Lippmann, Joshua W. Haines,\n",
            "           David J. Fried, Jonathan Korba, Kumar Das.\n",
            "\n",
            "    .. [3] K. Yamanishi, J.-I. Takeuchi, G. Williams, and P. Milne. Online\n",
            "           unsupervised outlier detection using finite mixtures with\n",
            "           discounting learning algorithms. In Proceedings of the sixth\n",
            "           ACM SIGKDD international conference on Knowledge discovery\n",
            "           and data mining, pages 320-324. ACM Press, 2000.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(D[\"DESCR\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4cef559d",
      "metadata": {
        "id": "4cef559d",
        "outputId": "63846f27-86db-4eba-c3d3-b27e61227575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'back.', b'buffer_overflow.', b'ftp_write.', b'guess_passwd.',\n",
              "       b'imap.', b'ipsweep.', b'land.', b'loadmodule.', b'multihop.',\n",
              "       b'neptune.', b'nmap.', b'normal.', b'perl.', b'phf.', b'pod.',\n",
              "       b'portsweep.', b'rootkit.', b'satan.', b'smurf.', b'spy.',\n",
              "       b'teardrop.', b'warezclient.', b'warezmaster.'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.unique(D[\"target\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6ed0289b",
      "metadata": {
        "id": "6ed0289b",
        "outputId": "7fc10001-8c8d-46d1-d419-d96e703cbb1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(np.unique(D[\"target\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aff034ea",
      "metadata": {
        "id": "aff034ea",
        "outputId": "bd1b65f2-7d53-4c77-b689-ac359ad65072",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['duration',\n",
              " 'protocol_type',\n",
              " 'service',\n",
              " 'flag',\n",
              " 'src_bytes',\n",
              " 'dst_bytes',\n",
              " 'land',\n",
              " 'wrong_fragment',\n",
              " 'urgent',\n",
              " 'hot',\n",
              " 'num_failed_logins',\n",
              " 'logged_in',\n",
              " 'num_compromised',\n",
              " 'root_shell',\n",
              " 'su_attempted',\n",
              " 'num_root',\n",
              " 'num_file_creations',\n",
              " 'num_shells',\n",
              " 'num_access_files',\n",
              " 'num_outbound_cmds',\n",
              " 'is_host_login',\n",
              " 'is_guest_login',\n",
              " 'count',\n",
              " 'srv_count',\n",
              " 'serror_rate',\n",
              " 'srv_serror_rate',\n",
              " 'rerror_rate',\n",
              " 'srv_rerror_rate',\n",
              " 'same_srv_rate',\n",
              " 'diff_srv_rate',\n",
              " 'srv_diff_host_rate',\n",
              " 'dst_host_count',\n",
              " 'dst_host_srv_count',\n",
              " 'dst_host_same_srv_rate',\n",
              " 'dst_host_diff_srv_rate',\n",
              " 'dst_host_same_src_port_rate',\n",
              " 'dst_host_srv_diff_host_rate',\n",
              " 'dst_host_serror_rate',\n",
              " 'dst_host_srv_serror_rate',\n",
              " 'dst_host_rerror_rate',\n",
              " 'dst_host_srv_rerror_rate']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "D[\"feature_names\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1"
      ],
      "metadata": {
        "id": "cw78B_TM3mRW"
      },
      "id": "cw78B_TM3mRW"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert features and target to DataFrames\n",
        "feature_df = pd.DataFrame(D.data, columns=D[\"feature_names\"])\n",
        "target_df = pd.Series(D.target).rename('target')\n",
        "\n",
        "# Concatenate features and target into a single DataFrame\n",
        "data_df = pd.concat([feature_df, target_df], axis=1)"
      ],
      "metadata": {
        "id": "8-_aGBh-U2Yz"
      },
      "id": "8-_aGBh-U2Yz",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cfd97ecd",
      "metadata": {
        "id": "cfd97ecd"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_kddcup99\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "D = fetch_kddcup99()\n",
        "\n",
        "\n",
        "categorical_features = ['protocol_type', 'service', 'flag']\n",
        "numerical_features = [f for f in D[\"feature_names\"] if f not in categorical_features]\n",
        "\n",
        "\n",
        "categorical_transformer = OneHotEncoder()\n",
        "numerical_transformer = StandardScaler()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "X = preprocessor.fit_transform(data_df.iloc[:, :-1])\n",
        "y = data_df['target'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "JhQxWch1UiRu"
      },
      "id": "JhQxWch1UiRu",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array([label.decode('utf-8') for label in y_train])\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)"
      ],
      "metadata": {
        "id": "V6PUg1VfV-kh"
      },
      "id": "V6PUg1VfV-kh",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXUpBBChWBWQ",
        "outputId": "64492ed7-a43f-4201-91de-3c00fe138cea"
      },
      "id": "cXUpBBChWBWQ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(345814,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define classifiers and their hyperparameter grids\n",
        "classifiers = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'LogisticRegression': LogisticRegression()\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    'RandomForest': {'n_estimators': [10, 50, 100], 'max_depth': [5, 10, None]},\n",
        "    'SVM': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
        "    'LogisticRegression': {'C': [0.1, 1, 10], 'max_iter': [100, 200]}\n",
        "}\n",
        "\n",
        "# Perform grid search for each classifier\n",
        "optimal_classifiers = {}\n",
        "# Proceed with training and hyperparameter tuning\n",
        "for clf_name in classifiers:\n",
        "    grid_search = GridSearchCV(classifiers[clf_name], param_grids[clf_name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    optimal_classifiers[clf_name] = grid_search.best_estimator_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrBgenO9VFRf",
        "outputId": "1dc0c637-a3fa-436c-ee83-844976638c86"
      },
      "id": "UrBgenO9VFRf",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = np.array([label.decode('utf-8') for label in y_val])"
      ],
      "metadata": {
        "id": "eWKtK555z7wp"
      },
      "id": "eWKtK555z7wp",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_encoded = label_encoder.transform(y_val)"
      ],
      "metadata": {
        "id": "lttS_ocKVUGL"
      },
      "id": "lttS_ocKVUGL",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#y_val_encoded should be in the same format as y_pred, and compute the accuracy\n",
        "for clf_name, clf in optimal_classifiers.items():\n",
        "    y_pred = clf.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val_encoded, y_pred)\n",
        "    print(f\"Accuracy of {clf_name}: {accuracy}\")"
      ],
      "metadata": {
        "id": "kr20wRyrXvCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91d6180-e96b-4c55-942d-050816f3b00e"
      },
      "id": "kr20wRyrXvCH",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of RandomForest: 0.9997570948544593\n",
            "Accuracy of SVM: 0.9994467160573796\n",
            "Accuracy of LogisticRegression: 0.9992173056421467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy = 0\n",
        "best_clf_name = None\n",
        "\n",
        "for clf_name, clf in optimal_classifiers.items():\n",
        "    y_val_pred = clf.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val_encoded, y_val_pred)\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_clf_name = clf_name\n",
        "\n",
        "print(f\"Best classifier on validation set: {best_clf_name} with accuracy: {best_accuracy}\")\n",
        "\n",
        "best_clf = optimal_classifiers[best_clf_name]\n",
        "\n",
        "\n",
        "y_test_pred = best_clf.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
        "print(f\"Test Accuracy of {best_clf_name}: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmwtVqVKzaYw",
        "outputId": "4faab3cc-08a9-4be7-d660-9cf39c1d2d83"
      },
      "id": "nmwtVqVKzaYw",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best classifier on validation set: RandomForest with accuracy: 0.9997570948544593\n",
            "Test Accuracy of RandomForest: 0.9997031199395444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
        "print(f\"Test Accuracy of {best_clf_name}: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0InljJP92-WW",
        "outputId": "85747035-15bf-4937-c517-e43caca645ad"
      },
      "id": "0InljJP92-WW",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of RandomForest: 0.9997031199395444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2"
      ],
      "metadata": {
        "id": "SMtq9gh039Hd"
      },
      "id": "SMtq9gh039Hd"
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_indices = [1, 2, 3]\n",
        "numerical_indices = [0, 4, 5]\n",
        "\n",
        "# Update the preprocessor to ignore unknown categories\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_indices),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_indices)\n",
        "    ])\n",
        "\n",
        "\n",
        "preprocessor.fit(X_train)\n",
        "\n",
        "# Transform both training and test data again\n",
        "X_train_encoded = preprocessor.transform(X_train)\n",
        "X_test_encoded = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "xJ2YB0cj4jW4"
      },
      "id": "xJ2YB0cj4jW4",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)"
      ],
      "metadata": {
        "id": "UjfALZxXVWPi"
      },
      "id": "UjfALZxXVWPi",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "ensemble_clf = RandomForestClassifier(n_estimators=25, random_state=42)\n",
        "\n",
        "ensemble_clf.fit(X_train_encoded, y_train_encoded)\n",
        "\n",
        "ensemble_predictions = ensemble_clf.predict_proba(X_test_encoded)"
      ],
      "metadata": {
        "id": "3lWLXkAU3_ro"
      },
      "id": "3lWLXkAU3_ro",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the maximum predicted probability for each sample\n",
        "max_probabilities = np.max(ensemble_predictions, axis=1)\n",
        "\n",
        "# Calculate the thresholds for the top and bottom 10%\n",
        "top_10_percent_threshold = np.percentile(max_probabilities, 90)\n",
        "bottom_10_percent_threshold = np.percentile(max_probabilities, 10)\n",
        "\n",
        "# Identify the top and bottom 10% of the data\n",
        "top_10_percent_indices = np.where(max_probabilities >= top_10_percent_threshold)[0]\n",
        "bottom_10_percent_indices = np.where(max_probabilities <= bottom_10_percent_threshold)[0]\n",
        "\n",
        "# Output the results\n",
        "print(f\"Indices of the top 10% uncertain data: {top_10_percent_indices}\")\n",
        "print(f\"Indices of the bottom 10% uncertain data: {bottom_10_percent_indices}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQUILI4m5tUI",
        "outputId": "73a8633b-2629-4bc2-cbb9-951447eaa32a"
      },
      "id": "EQUILI4m5tUI",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices of the top 10% uncertain data: [    0     1     2 ... 74100 74101 74102]\n",
            "Indices of the bottom 10% uncertain data: [    4    14    15 ... 74098 74099 74103]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3"
      ],
      "metadata": {
        "id": "EefrrVr061VZ"
      },
      "id": "EefrrVr061VZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 1"
      ],
      "metadata": {
        "id": "O1javIkY8gwo"
      },
      "id": "O1javIkY8gwo"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Instantiate a classifier to use with SelectFromModel\n",
        "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# Fit the classifier to get feature importances\n",
        "rf_classifier.fit(X_train_encoded, y_train_encoded)\n",
        "\n",
        "selector = SelectFromModel(rf_classifier, max_features=10, prefit=True)\n",
        "\n",
        "\n",
        "X_train_selected = selector.transform(X_train_encoded)\n",
        "X_test_selected = selector.transform(X_test_encoded)\n",
        "\n",
        "\n",
        "rf_classifier.fit(X_train_selected, y_train_encoded)\n",
        "y_pred_selected = rf_classifier.predict(X_test_selected)\n",
        "\n",
        "\n",
        "accuracy_selected = accuracy_score(y_test_encoded, y_pred_selected)"
      ],
      "metadata": {
        "id": "I6ZE5JkjPLMB"
      },
      "id": "I6ZE5JkjPLMB",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 2"
      ],
      "metadata": {
        "id": "h8SJoh9P8mTO"
      },
      "id": "h8SJoh9P8mTO"
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier.fit(X_train_encoded, y_train_encoded)\n",
        "\n",
        "importances = rf_classifier.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Select the top 10 most important features\n",
        "top_indices = indices[:10]\n",
        "X_train_top_features = X_train_encoded[:, top_indices]\n",
        "X_test_top_features = X_test_encoded[:, top_indices]\n",
        "\n",
        "# Train a classifier on the top features\n",
        "rf_classifier.fit(X_train_top_features, y_train_encoded)\n",
        "y_pred_top_features = rf_classifier.predict(X_test_top_features)\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy_top_features = accuracy_score(y_test_encoded, y_pred_top_features)\n"
      ],
      "metadata": {
        "id": "dNbSeIuA65Ut"
      },
      "id": "dNbSeIuA65Ut",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy with RFE selected features: {accuracy_selected}')\n",
        "print(f'Accuracy with top model features: {accuracy_top_features}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2v5l6mV9AW1",
        "outputId": "b0cc28dc-581e-4c57-b5ca-892e7c52d69c"
      },
      "id": "Q2v5l6mV9AW1",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with RFE selected features: 0.9782332937493253\n",
            "Accuracy with top model features: 0.9782332937493253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Excercise 4"
      ],
      "metadata": {
        "id": "yz2Th41ZR9QZ"
      },
      "id": "yz2Th41ZR9QZ"
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_classes = len(np.unique(y_train))"
      ],
      "metadata": {
        "id": "r_W8N_Gp6tDq"
      },
      "id": "r_W8N_Gp6tDq",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "PHQQtuuMSAh5"
      },
      "id": "PHQQtuuMSAh5",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import adjusted_rand_score\n",
        "\n",
        "# Split both the data and the labels\n",
        "X_sample, _, y_sample, _ = train_test_split(X_train_encoded, y_train, train_size=0.1, random_state=42)\n",
        "\n",
        "# Apply K-Means clustering\n",
        "kmeans = KMeans(n_clusters=number_of_classes, random_state=42)\n",
        "kmeans_labels_sample = kmeans.fit_predict(X_sample)\n",
        "\n",
        "# Calculate silhouette score\n",
        "silhouette_kmeans_sample = silhouette_score(X_sample, kmeans_labels_sample)\n",
        "print(f'Silhouette Score for K-Means (on sample): {silhouette_kmeans_sample}')\n",
        "\n",
        "# Calculate ARI\n",
        "ari_kmeans_sample = adjusted_rand_score(y_sample, kmeans_labels_sample)\n",
        "print(f'Adjusted Rand Index for K-Means (on sample): {ari_kmeans_sample}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QolCYZap3hfO",
        "outputId": "8c36a75a-1ffb-4e98-ed84-541695acabd3"
      },
      "id": "QolCYZap3hfO",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score for K-Means (on sample): 0.8196713888611975\n",
            "Adjusted Rand Index for K-Means (on sample): 0.7353621402635897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_indices = [1, 2, 3]\n",
        "numerical_indices = [0, 4, 5]\n",
        "\n",
        "# Update the preprocessor to ignore unknown categories\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_indices),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_indices)\n",
        "    ])\n",
        "\n",
        "\n",
        "preprocessor.fit(X_train)\n",
        "\n",
        "# Transform both training and test data again\n",
        "X_train_encoded = preprocessor.transform(X_train)\n",
        "X_test_encoded = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "10KzoXPf_g3o"
      },
      "id": "10KzoXPf_g3o",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_sample, _ = train_test_split(X_train_encoded, train_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "AEaAMosv_bQp"
      },
      "id": "AEaAMosv_bQp",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "\n",
        "X_sample_reduced, _, y_sample_reduced, _ = train_test_split(X_sample, y_sample, train_size=0.05, random_state=42)\n",
        "\n",
        "# Convert to dense format and apply Agglomerative Clustering\n",
        "X_sample_reduced_dense = X_sample_reduced.toarray()\n",
        "agg_clustering_reduced = AgglomerativeClustering(n_clusters=number_of_classes)\n",
        "agg_labels_reduced = agg_clustering_reduced.fit_predict(X_sample_reduced_dense)\n",
        "\n",
        "# Calculate the silhouette score\n",
        "silhouette_agg_reduced = silhouette_score(X_sample_reduced_dense, agg_labels_reduced)\n",
        "print(f'Silhouette Score for Agglomerative Clustering (reduced sample): {silhouette_agg_reduced}')\n",
        "\n",
        "# Calculate the ARI\n",
        "ari_agg_reduced = adjusted_rand_score(y_sample_reduced, agg_labels_reduced)\n",
        "print(f'Adjusted Rand Index for Agglomerative Clustering (reduced sample): {ari_agg_reduced}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrsdvtRj4Dx7",
        "outputId": "1b584fd1-a0eb-4b50-fa78-13f4910277bb"
      },
      "id": "RrsdvtRj4Dx7",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score for Agglomerative Clustering (reduced sample): 0.8447762623234524\n",
            "Adjusted Rand Index for Agglomerative Clustering (reduced sample): 0.7136785767939295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sample, _ = train_test_split(X_train_encoded, train_size=0.05, random_state=42)  # Sample 5% of the data\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "dbscan_labels = dbscan.fit_predict(X_train_sample)\n",
        "\n",
        "\n",
        "if len(set(dbscan_labels)) > 1:\n",
        "    silhouette_dbscan = silhouette_score(X_train_sample, dbscan_labels)\n",
        "    print(f'Silhouette Score for DBSCAN: {silhouette_dbscan}')\n",
        "else:\n",
        "    print(\"DBSCAN found less than 2 clusters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80TUaToCCyBS",
        "outputId": "36a4ce5f-b5c1-41f8-e251-f48b07e4b916"
      },
      "id": "80TUaToCCyBS",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score for DBSCAN: 0.8119808331882435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "\n",
        "X_train_sample, _, y_train_sample, _ = train_test_split(X_train_encoded, y_train, train_size=0.05, random_state=42)\n",
        "\n",
        "\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "dbscan_labels = dbscan.fit_predict(X_train_sample)\n",
        "\n",
        "if len(set(dbscan_labels)) > 1:\n",
        "    silhouette_dbscan = silhouette_score(X_train_sample, dbscan_labels)\n",
        "    print(f'Silhouette Score for DBSCAN: {silhouette_dbscan}')\n",
        "    # Calculate the ARI\n",
        "    ari_dbscan = adjusted_rand_score(y_train_sample, dbscan_labels)\n",
        "    print(f'Adjusted Rand Index for DBSCAN: {ari_dbscan}')\n",
        "else:\n",
        "    print(\"DBSCAN found less than 2 clusters\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2DhkP534k7A",
        "outputId": "3f3a04a4-a687-4ec7-f93a-6f7e3182ebe6"
      },
      "id": "i2DhkP534k7A",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score for DBSCAN: 0.8119808331882435\n",
            "Adjusted Rand Index for DBSCAN: 0.7378514667998353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 6"
      ],
      "metadata": {
        "id": "h8mPh2zz2GCQ"
      },
      "id": "h8mPh2zz2GCQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import classification_report, roc_auc_score"
      ],
      "metadata": {
        "id": "nP0IsnGkEI60"
      },
      "id": "nP0IsnGkEI60",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = fetch_kddcup99()\n",
        "df = fetch_kddcup99(as_frame=True)"
      ],
      "metadata": {
        "id": "80vZouWY2keo"
      },
      "id": "80vZouWY2keo",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, target = df['data'], df['target']"
      ],
      "metadata": {
        "id": "a3mIeNb92nYZ"
      },
      "id": "a3mIeNb92nYZ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SA_data, SA_target = data, target\n",
        "X_train, X_test, y_train, y_test = train_test_split(SA_data, SA_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "tFUk2D0R2652"
      },
      "id": "tFUk2D0R2652",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Anomaly Detection algorithms\n",
        "iso_forest = IsolationForest()\n",
        "oc_svm = OneClassSVM()\n",
        "lof = LocalOutlierFactor()"
      ],
      "metadata": {
        "id": "WCTNK3X25AbK"
      },
      "id": "WCTNK3X25AbK",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_sample, _ = train_test_split(X_train, train_size=0.1, random_state=42)  # Sample 10% of the data\n",
        "X_sample, _, y_sample, _ = train_test_split(X_train_encoded, y_train, train_size=0.1, random_state=42)\n"
      ],
      "metadata": {
        "id": "ED65dr39GycP"
      },
      "id": "ED65dr39GycP",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Using a smaller sample of the data\n",
        "iso_forest_pred = iso_forest.fit_predict(X_train_sample)\n",
        "oc_svm_pred = oc_svm.fit_predict(X_train_sample)\n",
        "lof_pred = lof.fit_predict(X_train_sample)\n"
      ],
      "metadata": {
        "id": "9MDd_qaAGs2P"
      },
      "id": "9MDd_qaAGs2P",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Isolation Forest Performance on Sample:\")\n",
        "print(classification_report(y_sample, iso_forest_pred))\n",
        "\n",
        "print(\"One-Class SVM Performance on Sample:\")\n",
        "print(classification_report(y_sample, oc_svm_pred))\n",
        "\n",
        "print(\"Local Outlier Factor Performance on Sample:\")\n",
        "print(classification_report(y_sample, lof_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xnByVVm5C1i",
        "outputId": "87727aa2-cfad-4f23-a855-e85d0fe99969"
      },
      "id": "5xnByVVm5C1i",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isolation Forest Performance on Sample:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00       0.0\n",
            "           0       0.00      0.00      0.00     180.0\n",
            "           1       0.00      0.00      0.00       2.0\n",
            "           2       0.00      0.00      0.00       2.0\n",
            "           3       0.00      0.00      0.00       3.0\n",
            "           4       0.00      0.00      0.00       1.0\n",
            "           5       0.00      0.00      0.00      79.0\n",
            "           6       0.00      0.00      0.00       1.0\n",
            "           7       0.00      0.00      0.00       1.0\n",
            "           8       0.00      0.00      0.00       1.0\n",
            "           9       0.00      0.00      0.00    8680.0\n",
            "          10       0.00      0.00      0.00      14.0\n",
            "          11       0.00      0.00      0.00    7796.0\n",
            "          14       0.00      0.00      0.00      19.0\n",
            "          15       0.00      0.00      0.00      83.0\n",
            "          16       0.00      0.00      0.00       2.0\n",
            "          17       0.00      0.00      0.00     141.0\n",
            "          18       0.00      0.00      0.00   22366.0\n",
            "          20       0.00      0.00      0.00      69.0\n",
            "          21       0.00      0.00      0.00      80.0\n",
            "          22       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00   39521.0\n",
            "   macro avg       0.00      0.00      0.00   39521.0\n",
            "weighted avg       0.00      0.00      0.00   39521.0\n",
            "\n",
            "One-Class SVM Performance on Sample:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00       0.0\n",
            "           0       0.00      0.00      0.00     180.0\n",
            "           1       0.00      0.00      0.00       2.0\n",
            "           2       0.00      0.00      0.00       2.0\n",
            "           3       0.00      0.00      0.00       3.0\n",
            "           4       0.00      0.00      0.00       1.0\n",
            "           5       0.00      0.00      0.00      79.0\n",
            "           6       0.00      0.00      0.00       1.0\n",
            "           7       0.00      0.00      0.00       1.0\n",
            "           8       0.00      0.00      0.00       1.0\n",
            "           9       0.00      0.00      0.00    8680.0\n",
            "          10       0.00      0.00      0.00      14.0\n",
            "          11       0.00      0.00      0.00    7796.0\n",
            "          14       0.00      0.00      0.00      19.0\n",
            "          15       0.00      0.00      0.00      83.0\n",
            "          16       0.00      0.00      0.00       2.0\n",
            "          17       0.00      0.00      0.00     141.0\n",
            "          18       0.00      0.00      0.00   22366.0\n",
            "          20       0.00      0.00      0.00      69.0\n",
            "          21       0.00      0.00      0.00      80.0\n",
            "          22       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00   39521.0\n",
            "   macro avg       0.00      0.00      0.00   39521.0\n",
            "weighted avg       0.00      0.00      0.00   39521.0\n",
            "\n",
            "Local Outlier Factor Performance on Sample:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00         0\n",
            "           0       0.00      0.00      0.00       180\n",
            "           1       0.00      0.50      0.00         2\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00        79\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.00      0.00      0.00      8680\n",
            "          10       0.00      0.00      0.00        14\n",
            "          11       0.00      0.00      0.00      7796\n",
            "          14       0.00      0.00      0.00        19\n",
            "          15       0.00      0.00      0.00        83\n",
            "          16       0.00      0.00      0.00         2\n",
            "          17       0.00      0.00      0.00       141\n",
            "          18       0.00      0.00      0.00     22366\n",
            "          20       0.00      0.00      0.00        69\n",
            "          21       0.00      0.00      0.00        80\n",
            "          22       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.00     39521\n",
            "   macro avg       0.00      0.02      0.00     39521\n",
            "weighted avg       0.00      0.00      0.00     39521\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 7"
      ],
      "metadata": {
        "id": "HoUNQMQ8KcgH"
      },
      "id": "HoUNQMQ8KcgH"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, LeaveOneOut\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "id": "Ce2fWppMLDCW"
      },
      "id": "Ce2fWppMLDCW",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_subsample, _, y_subsample, _ = train_test_split(X, y, train_size=250, stratify=y, random_state=4)"
      ],
      "metadata": {
        "id": "pQsMo-36J8NB"
      },
      "id": "pQsMo-36J8NB",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iso_forest = IsolationForest()\n",
        "oc_svm = OneClassSVM()\n",
        "lof = LocalOutlierFactor(novelty=True)"
      ],
      "metadata": {
        "id": "90exa4SgKjvL"
      },
      "id": "90exa4SgKjvL",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loo = LeaveOneOut()"
      ],
      "metadata": {
        "id": "U2np6vO2KoxQ"
      },
      "id": "U2np6vO2KoxQ",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, iso_forest_preds, oc_svm_preds, lof_preds = [], [], [], []"
      ],
      "metadata": {
        "id": "NEe3upc2LR8R"
      },
      "id": "NEe3upc2LR8R",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists for true labels and predictions\n",
        "y_true = []\n",
        "iso_forest_preds = []\n",
        "oc_svm_preds = []\n",
        "lof_preds = []"
      ],
      "metadata": {
        "id": "Ctonon5BMR52"
      },
      "id": "Ctonon5BMR52",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train_index, test_index in loo.split(X_subsample):\n",
        "    X_train, X_test = X_subsample[train_index], X_subsample[test_index]\n",
        "    y_train, y_test = y_subsample[train_index], y_subsample[test_index]\n",
        "\n",
        "    # Append true label for this iteration\n",
        "    y_true.append(y_test[0])\n",
        "\n",
        "    # Isolation Forest\n",
        "    iso_forest.fit(X_train, y_train)\n",
        "    iso_forest_preds.append(iso_forest.predict(X_test)[0])\n",
        "\n",
        "    # One-Class SVM\n",
        "    oc_svm.fit(X_train, y_train)\n",
        "    oc_svm_preds.append(oc_svm.predict(X_test)[0])\n",
        "\n",
        "    # Local Outlier Factor\n",
        "    lof.fit(X_train, y_train)\n",
        "    lof_preds.append(lof.predict(X_test)[0])\n"
      ],
      "metadata": {
        "id": "oOe68bXwLUtL"
      },
      "id": "oOe68bXwLUtL",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert lists to numpy arrays\n",
        "y_true = np.array(y_true)\n",
        "iso_forest_preds = np.array(iso_forest_preds)\n",
        "oc_svm_preds = np.array(oc_svm_preds)\n",
        "lof_preds = np.array(lof_preds)"
      ],
      "metadata": {
        "id": "TpPNHEu1LXJE"
      },
      "id": "TpPNHEu1LXJE",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anomaly_labels = ['smurf.', 'neptune.', ...]\n",
        "y_true_numeric = np.array([-1 if label in anomaly_labels else 1 for label in y_true])"
      ],
      "metadata": {
        "id": "niOWSuvhQJ54"
      },
      "id": "niOWSuvhQJ54",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recalculate the metrics\n",
        "print(f\"Performance metrics for {model_name}:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_true_numeric, predictions)}\")\n",
        "print(f\"Precision: {precision_score(y_true_numeric, predictions, pos_label=-1)}\")\n",
        "print(f\"Recall: {recall_score(y_true_numeric, predictions, pos_label=-1)}\")\n",
        "print(f\"F1 Score: {f1_score(y_true_numeric, predictions, pos_label=-1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFRe_A2HP5Fw",
        "outputId": "70efe13f-d1ff-4deb-aef3-8bc8dad418be"
      },
      "id": "JFRe_A2HP5Fw",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance metrics for Isolation Forest:\n",
            "Accuracy: 0.208\n",
            "Precision: 0.4583333333333333\n",
            "Recall: 0.05612244897959184\n",
            "F1 Score: 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 8"
      ],
      "metadata": {
        "id": "lRo0rEpKQeM9"
      },
      "id": "lRo0rEpKQeM9"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Label type:\", type(y_subsample[0]))\n",
        "print(\"Unique labels:\", np.unique(y_subsample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MsdVIQLSD0x",
        "outputId": "889ceade-3207-4e8b-c7e7-ae1380b7d838"
      },
      "id": "7MsdVIQLSD0x",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label type: <class 'bytes'>\n",
            "Unique labels: [b'back.' b'ipsweep.' b'neptune.' b'normal.' b'portsweep.' b'satan.'\n",
            " b'smurf.' b'warezclient.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_subsample_encoded = label_encoder.fit_transform(y_subsample)"
      ],
      "metadata": {
        "id": "MO6h4kgjSFeO"
      },
      "id": "MO6h4kgjSFeO",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Initialize RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_subsample, y_subsample_encoded)\n",
        "\n",
        "\n",
        "# Select the top 5 features\n",
        "selector = SelectFromModel(rf, max_features=5, prefit=True)\n",
        "X_subsample_selected = selector.transform(X_subsample)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_features_indices = selector.get_support(indices=True)\n",
        "print(\"Selected feature indices:\", selected_features_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWUpSRXHL881",
        "outputId": "7e782adf-5dce-4e50-baea-96b4a363de9b"
      },
      "id": "VWUpSRXHL881",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected feature indices: [19 20 32 38 55]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Isolation Forest\n",
        "iso_forest_selected = IsolationForest()\n",
        "iso_forest_selected.fit(X_subsample_selected)\n",
        "\n",
        "# One-Class SVM\n",
        "oc_svm_selected = OneClassSVM()\n",
        "oc_svm_selected.fit(X_subsample_selected)\n",
        "\n",
        "# Local Outlier Factor\n",
        "lof_selected = LocalOutlierFactor(novelty=True)\n",
        "lof_selected.fit(X_subsample_selected)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "4AaRH-ZERFdz",
        "outputId": "fe94ef76-0d97-4284-e471-3c328d9617ca"
      },
      "id": "4AaRH-ZERFdz",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LocalOutlierFactor(novelty=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LocalOutlierFactor(novelty=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LocalOutlierFactor</label><div class=\"sk-toggleable__content\"><pre>LocalOutlierFactor(novelty=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_selected = selector.transform(X_test)"
      ],
      "metadata": {
        "id": "paL4rFfiSU6y"
      },
      "id": "paL4rFfiSU6y",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "anomaly_labels = ['smurf.', 'neptune.', ...]\n",
        "y_test_binary = np.array([-1 if label in anomaly_labels else 1 for label in y_test])"
      ],
      "metadata": {
        "id": "zrvrw7E7TXfs"
      },
      "id": "zrvrw7E7TXfs",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Isolation Forest on Selected Features:\")\n",
        "print(classification_report(y_test_binary, iso_forest_pred_test))\n",
        "\n",
        "oc_svm_pred_test = oc_svm_selected.predict(X_test_selected)\n",
        "print(\"One-Class SVM on Selected Features:\")\n",
        "print(classification_report(y_test_binary, oc_svm_pred_test))\n",
        "\n",
        "lof_pred_test = lof_selected.predict(X_test_selected)\n",
        "print(\"Local Outlier Factor on Selected Features:\")\n",
        "print(classification_report(y_test_binary, lof_pred_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKNaErWVSulU",
        "outputId": "c20e5418-9795-463a-ab9b-70f98bbdbeab"
      },
      "id": "xKNaErWVSulU",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isolation Forest on Selected Features:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         1\n",
            "   macro avg       1.00      1.00      1.00         1\n",
            "weighted avg       1.00      1.00      1.00         1\n",
            "\n",
            "One-Class SVM on Selected Features:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00       0.0\n",
            "           1       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00       1.0\n",
            "   macro avg       0.00      0.00      0.00       1.0\n",
            "weighted avg       0.00      0.00      0.00       1.0\n",
            "\n",
            "Local Outlier Factor on Selected Features:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         1\n",
            "   macro avg       1.00      1.00      1.00         1\n",
            "weighted avg       1.00      1.00      1.00         1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CpGb86CBSytF"
      },
      "id": "CpGb86CBSytF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}